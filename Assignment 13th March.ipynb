{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b1071-b619-46dd-9946-1b0b9e6f5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means across two or more groups. To use ANOVA and interpret its results correctly, several assumptions must be met:\n",
    "Independence: Observations within each group must be independent of each other. This means that the data points in one group should not be influenced by or dependent on the data points in another group. Violations of this assumption can occur when data points within groups are correlated, such as in repeated measures designs or nested data structures.\n",
    "Normality: The residuals (the differences between the observed values and the predicted values) should be normally distributed for each group. While ANOVA is robust to violations of normality when sample sizes are large, departures from normality can affect the accuracy of p-values and confidence intervals, especially with small sample sizes.\n",
    "Homogeneity of variances (Homoscedasticity): The variability of the dependent variable should be approximately equal across all groups. This means that the spread of data points around the group means should be similar for all groups. Violations of homogeneity of variances can lead to inaccurate p-values and confidence intervals, particularly when sample sizes are unequal.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "Non-independence: In a study where individuals are grouped by family or household, the assumption of independence may be violated because observations within the same family or household may be correlated.\n",
    "Non-normality: If the residuals from the ANOVA model are not normally distributed within each group, this could affect the accuracy of the p-values and confidence intervals. For example, if the residuals are highly skewed or have heavy tails, the assumption of normality may be violated.\n",
    "Non-homogeneity of variances: In a study comparing the effectiveness of different teaching methods across schools, if the variability of test scores within each school is not consistent across all schools, the assumption of homogeneity of variances may be violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fdc53-e22e-4046-9e42-4d9d170c803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "Each type of ANOVA is used in different situations based on the number of independent variables and their levels:\n",
    "\n",
    "One-way ANOVA: Used when comparing the means of three or more independent groups or levels of a single categorical variable. For example, comparing the mean test scores of students in three different teaching methods (Group 1: Traditional, Group 2: Online, Group 3: Blended).\n",
    "Two-way ANOVA: Used when examining the effects of two independent categorical variables (factors) on a continuous dependent variable. For example, examining the effects of both gender (Factor 1: Male vs. Female) and age group (Factor 2: Young Adults vs. Middle-aged Adults) on blood pressure.\n",
    "N-way ANOVA: Used when examining the effects of multiple independent categorical variables (factors) on a continuous dependent variable, with more than two levels for each factor. For example, examining the effects of education level (Factor 1: High School, Bachelor's, Master's, Ph.D.), gender (Factor 2: Male vs. Female), and age group (Factor 3: Young Adults, Middle-aged Adults, Seniors) on income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf755250-2dd4-46a1-b86c-cdbfc3d23d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "#The partitioning of variance in ANOVA refers to breaking down total variance into between-group and within-group variances. It's important because it helps understand how much of the variability in the dependent variable is due to differences between groups and how much is due to differences within groups, aiding in the interpretation of results and identification of sources of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d7f08c-b25c-4049-a444-e44fe0a592a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Means:\n",
      "Group 1: 27.4\n",
      "Group 2: 25.0\n",
      "Group 3: 23.4\n",
      "\n",
      "Total Sum of Squares (SST): 224.93333333333337\n",
      "Explained Sum of Squares (SSE): 40.53333333333333\n",
      "Residual Sum of Squares (SSR): 184.40000000000003\n"
     ]
    }
   ],
   "source": [
    "#Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for one-way ANOVA\n",
    "group1 = [23, 25, 27, 30, 32]\n",
    "group2 = [20, 22, 25, 28, 30]\n",
    "group3 = [18, 21, 24, 26, 28]\n",
    "\n",
    "# Combine all groups into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate overall mean (Grand Mean)\n",
    "grand_mean = np.mean(data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "sst = np.sum((data - grand_mean) ** 2)\n",
    "\n",
    "# Calculate group means\n",
    "group_means = [np.mean(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "sse = np.sum([len(group) * (mean - grand_mean) ** 2 for group, mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Output group means\n",
    "print(\"Group Means:\")\n",
    "for i, mean in enumerate(group_means, start=1):\n",
    "    print(f\"Group {i}: {mean}\")\n",
    "\n",
    "print(\"\\nTotal Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a5df0-d5bd-41d9-b5df-0a8e0c0b7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('dependent_variable ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data=df).fit()\n",
    "\n",
    "# Analyze main effects\n",
    "main_effects = anova_lm(model, typ=2)\n",
    "\n",
    "# Analyze interaction effect\n",
    "interaction_effect = model.params['C(factor1):C(factor2)[T.level]']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc0a52-9b50-4a55-835b-5b54476f9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "In this scenario:\n",
    "\n",
    "F-statistic = 5.23\n",
    "p-value = 0.02\n",
    "Since the p-value (0.02) is less than the commonly chosen significance level of 0.05, we reject the null hypothesis. This means that there is sufficient evidence to conclude that there are statistically significant differences between the groups.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The differences between the groups are statistically significant, as indicated by the low p-value.\n",
    "The F-statistic (5.23) further supports the evidence of differences between the groups.\n",
    "In summary, based on the results of the one-way ANOVA:\n",
    "\n",
    "We reject the null hypothesis of equal group means.\n",
    "There are statistically significant differences between the groups.\n",
    "This suggests that at least one group mean is different from the others, but further post-hoc tests or pairwise comparisons would be needed to determine which specific groups differ from each othe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c81bac-3fb0-4e5c-9712-2513a4e527a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "Listwise deletion: Exclude cases with missing data from the analysis entirely. This approach ensures that only complete cases are included in the analysis.\n",
    "Pairwise deletion: Analyze only the available data for each pairwise combination of variables. This approach maximizes the use of available data but may lead to biased estimates if data are not missing completely at random.\n",
    "Mean substitution: Replace missing values with the mean of the observed values for that variable. This approach preserves the sample size but can distort the variance and covariance structure of the data.\n",
    "Last observation carried forward (LOCF): Replace missing values with the last observed value for that variable. This approach assumes that missing values remain constant over time and may introduce bias if this assumption is violated.\n",
    "Interpolation: Estimate missing values based on the observed values before and after the missing data point. This approach assumes a linear or nonlinear trend between observed data points and may provide more accurate estimates than mean substitution or LOCF.\n",
    "Multiple imputation: Generate multiple plausible values for each missing data point based on observed data and impute them using statistical models. This approach accounts for uncertainty associated with missing data and provides more accurate parameter estimates than single imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783ff9b-4ce0-4b7e-8411-db87999deb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Common Post-Hoc Tests Used After ANOVA:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) Test\n",
    "Bonferroni Correction\n",
    "Scheffé Test\n",
    "Dunnett's Test\n",
    "Fisher's Least Significant Difference (LSD) Test\n",
    "Games-Howell Test\n",
    "Sidak Correction\n",
    "Example Situation:\n",
    "Suppose you conducted a one-way ANOVA to compare the mean scores of three different teaching methods (A, B, and C) on student performance. The ANOVA results indicate that there is a statistically significant difference among the means of the three groups (p < 0.05). However, ANOVA does not provide information on which specific groups differ from each other. In this case, a post-hoc test is necessary to determine pairwise differences between the teaching methods.\n",
    "\n",
    "You would use each post-hoc test based on specific considerations such as the assumptions of the test, the number of comparisons being made, and the desired level of significance. For example:\n",
    "\n",
    "Tukey's HSD test is commonly used when all pairwise comparisons need to be made and assumes equal sample sizes and homogeneity of variances.\n",
    "Bonferroni correction is a conservative method that adjusts the significance level to control the familywise error rate when conducting multiple comparisons.\n",
    "Scheffé test is more robust and suitable for situations where sample sizes are unequal or variances are unequal across groups.\n",
    "Dunnett's test is appropriate when comparing multiple treatment groups to a control group.\n",
    "Fisher's LSD test is a simple and less conservative method suitable for comparing two treatment groups.\n",
    "The choice of post-hoc test depends on the specific research question, assumptions, and desired level of control for Type I error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd8bdce0-4223-4b3e-acf2-115a031ec9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 0.32571598650704403\n",
      "P-Value: 0.7225299512887295\n",
      "Fail to reject the null hypothesis. There is no significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "#Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "#random value of the diests of 50 random samples\n",
    "diet_a = np.round(np.random.uniform(1.5,2.9,50),1)\n",
    "diet_b = np.round(np.random.uniform(1.5,2.9,50),1)\n",
    "diet_c = np.round(np.random.uniform(1.5,2.9,50),1)\n",
    "#to calculate the f_statistics and p_value for the given alpha 0.05\n",
    "alpha=0.05\n",
    "f_statistics,p_value=f_oneway(diet_a,diet_b,diet_c)\n",
    "print(\"F-Statistic:\", f_statistics)\n",
    "print(\"P-Value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fec7ea20-f654-4901-a06c-3e700aafe9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq    df         F    PR(>F)\n",
      "C(Software)                11.141545   2.0  2.113814  0.142706\n",
      "C(Experience)               2.102143   1.0  0.797652  0.380665\n",
      "C(Software):C(Experience)   6.013261   2.0  1.140857  0.336272\n",
      "Residual                   63.249921  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "#complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# Generate sample data\n",
    "np.random.seed(0)  # for reproducibility\n",
    "n = 30\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], n)\n",
    "experience_levels = np.random.choice(['Novice', 'Experienced'], n)\n",
    "task_completion_time = np.random.normal(loc=10, scale=2, size=n)  # sample task completion times\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Software': software_programs, 'Experience': experience_levels, 'Time': task_completion_time})\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbb40ab9-6d97-4e70-ae13-5a0391d45ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -5.3443793223209415\n",
      "P-Value: 2.4835668985382e-07\n",
      "There is a significant difference in test scores between the control group and the experimental group.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj   lower  upper reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   0.7194 0.6298 -2.2191 3.658  False\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "#two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "#np.random.seed(0)  # for reproducibility\n",
    "control_group_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_group_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the control group and the experimental group.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control group and the experimental group.\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    # Combine the test scores and group labels into a single DataFrame\n",
    "    data = np.vstack((control_group_scores, experimental_group_scores)).T\n",
    "    labels = ['Control'] * 100 + ['Experimental'] * 100\n",
    "\n",
    "    # Perform Tukey's HSD test\n",
    "    tukey_results = pairwise_tukeyhsd(data.flatten(), labels, alpha=0.05)\n",
    "    print(tukey_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b75850-d7bd-4859-a863-3100e7d71d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "#significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "np.random.seed(0)  # for reproducibility# it is used to stop the changing nature of the random varibales.\n",
    "store_a_sales = np.random.normal(loc=100, scale=20, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=20, size=30)\n",
    "store_c_sales = np.random.normal(loc=120, scale=20, size=30)\n",
    "sales_data = pd.DataFrame({\n",
    "    'Store A': store_a_sales,\n",
    "    'Store B': store_b_sales,\n",
    "    'Store C': store_c_sales\n",
    "})\n",
    "# Perform the repeated measures ANOVA with automatic aggregation\n",
    "anova_rm = AnovaRM(sales_data, sales_data.columns, 'subject', within=['variable'], aggregate_func='mean')\n",
    "anova_results = anova_rm.fit()\n",
    "print(anova_results.anova_table['Pr > F'])\n",
    "\n",
    "\n",
    "if anova_results.pvalues['variable'] < 0.05:\n",
    "    # Perform Tukey's HSD test\n",
    "    tukey_results = pairwise_tukeyhsd(sales_data.melt()['value'], sales_data.melt()['variable'], alpha=0.05)\n",
    "    print(tukey_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
